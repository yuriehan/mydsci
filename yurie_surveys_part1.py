# -*- coding: utf-8 -*-
"""yurie_surveys_part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cs5vyTOSqZJl5VmTQaj94wywNz4z_64L
"""

import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from google.colab import files
import matplotlib.pyplot as plt

surveyFiles = [
    '2024 Subscriber Survey_Full Demo_September 16, 2024_10.27.csv',
    '2024 Subscriber Survey_Partial Demo_September 16, 2024_10.28.csv',
    'DG Post-Performance Survey - Demographics_May 22, 2024_11.14.csv',
    'FY24 Falstaff Post-Performance Survey_May 22, 2024_11.38.csv',
    'Intelligence Post-Performance Survey_May 22, 2024_11.37.csv',
    'MB Post-Performance Survey - Demographics_May 22, 2024_11.24.csv'
]

# Read '2024 Subscriber Survey_Full Demo_September 16, 2024_10.27.csv'
df0 = pd.read_csv(surveyFiles[0], skiprows = [2]) # First rows skipped because irrelevant

# If someone responds with "Other" in a column, replace it with their corresponding text response in the next column
df0.loc[df0['Q204'] == 'Other', 'Q204'] = df0.loc[df0['Q204'] == 'Other', 'Q204_8_TEXT']
df0.loc[df0['Q195'].str.contains('Other', na=False), 'Q195'] = df0.loc[df0['Q195'].str.contains('Other', na=False), 'Q195_9_TEXT']
df0.loc[df0['Q206'] == 'Other', 'Q206'] = df0.loc[df0['Q206'] == 'Other', 'Q206_8_TEXT']
df0.loc[df0['Q210'].str.contains('Please list any other performing arts companies you support', na=False), 'Q210'] = df0.loc[df0['Q210'].str.contains('Please list any other performing arts companies you support', na=False), 'Q210_9_TEXT']
df0.loc[df0['Q231'].str.contains('Other', na=False), 'Q231'] = df0.loc[df0['Q231'].str.contains('Other', na=False), 'Q231_11_TEXT']
df0.loc[df0['Q212'] == 'Other', 'Q212'] = df0.loc[df0['Q212'] == 'Other', 'Q212_8_TEXT']
df0.loc[df0['Q211'].str.contains('Other', na=False), 'Q211'] = df0.loc[df0['Q211'].str.contains('Other', na=False), 'Q211_13_TEXT']
df0.loc[df0['Q214'].str.contains('Other', na=False), 'Q214'] = df0.loc[df0['Q214'].str.contains('Other', na=False), 'Q214_11_TEXT']
df0.loc[df0['Q216'].str.contains('Other', na=False), 'Q216'] = df0.loc[df0['Q216'].str.contains('Other', na=False), 'Q216_7_TEXT']
df0.loc[df0['Q217'].str.contains('Other', na=False), 'Q217'] = df0.loc[df0['Q217'].str.contains('Other', na=False), 'Q217_8_TEXT']
df0.loc[df0['Q26'].str.contains('Other Race or Ethnicity', na=False), 'Q26'] = df0.loc[df0['Q26'].str.contains('Other Race or Ethnicity', na=False), 'Q26_13_TEXT']
df0.loc[df0['Q161'] == 'Other', 'Q161'] = df0.loc[df0['Q161'] == 'Other', 'Q161_3_TEXT']
df0.loc[df0['Q162'].str.contains('Other', na=False), 'Q162'] = df0.loc[df0['Q162'].str.contains('Other', na=False), 'Q162_3_TEXT']
df0.loc[df0['Q165'].str.contains('Other', na=False), 'Q165'] = df0.loc[df0['Q165'].str.contains('Other', na=False), 'Q165_19_TEXT']

preferences_mapping = {
    'Q205_1': 'Mailed print materials',
    'Q205_4': 'Emails',
    'Q205_5': 'Phone calls',
    'Q205_6': 'Social media',
    'Q205_7': 'HGO.org',
    'Q205_9': 'Opera Cues',
    'Q205_8': 'Other'
}

def combine_preferences(row):
    # Filter out missing values (NaN) and rank preferences
    ranked_methods = sorted(
        [(row[col], preferences_mapping[col]) for col in preferences_mapping.keys() if pd.notna(row[col])],
        key=lambda x: x[0]
    )

    # If there are no ranked preferences, return an empty string
    if not ranked_methods:
        return ''

    # Otherwise, return the ranked preferences as a string
    return ', '.join([f"{rank}: {method}" for rank, method in ranked_methods])

# Apply function to each row
df0['Q205_1'] = df0.apply(combine_preferences, axis=1)

# Drop the irrelevant columns, decided based on potential important features
columns_to_remove = ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',
                      'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage', 'Q194_1', 'Q194_2', 'Q194_3', 'Q195_9_TEXT',
                      'Q197', 'Q205_4', 'Q205_5', 'Q205_6', 'Q205_7', 'Q205_8', 'Q205_9',
                       'Q200_1',	'Q200_4',	'Q200_5',	'Q200_6',	'Q200_7',	'Q200_8',	'Q200_9',	'Q200_11', 'Q200_11_TEXT',
                       'Q202', 'Q204_8_TEXT', 'Q205_8_TEXT', 'Q206_8_TEXT', 'Q202',
                      'Q207', 'Q208', 'Q210_9_TEXT', 'Q211_13_TEXT', 'Q212_8_TEXT', 'Q214_11_TEXT', 'Q216_7_TEXT', 'Q217_8_TEXT', 'Q218_3_TEXT', 'Q218_8_TEXT', 'Q218_9_TEXT',
                       'Q26_13_TEXT', 'Q161_3_TEXT', 'Q162_3_TEXT', 'Q165_19_TEXT', 'Q218_10_TEXT', 'Q222', 'Q231_11_TEXT',
                       'SolutionRevision', 'ProjectCategory', 'ProjectType']
df0 = df0.drop(columns=columns_to_remove)

# Read '2024 Subscriber Survey_Partial Demo_September 16, 2024_10.28.csv'
df1 = pd.read_csv(surveyFiles[1], skiprows=[2]) # First rows skipped because irrelevant

# If someone responds with "Other" in a column, replace it with their corresponding text response in the next column
df1.loc[df1['Q195'].str.contains('Other', na=False), 'Q195'] = df1.loc[df1['Q195'].str.contains('Other', na=False), 'Q195_9_TEXT']
df1.loc[df1['Q206'] == 'Other', 'Q206'] = df1.loc[df1['Q206'] == 'Other', 'Q206_8_TEXT']
df1.loc[df1['Q204'] == 'Other', 'Q204'] = df1.loc[df1['Q204'] == 'Other', 'Q204_8_TEXT']
df1.loc[df1['Q210'].str.contains('Please list any other performing arts companies you support', na=False), 'Q210'] = df1.loc[df1['Q210'].str.contains('Please list any other performing arts companies you support', na=False), 'Q210_9_TEXT']
df1.loc[df1['Q231'].str.contains('Other', na=False), 'Q231'] = df1.loc[df1['Q231'].str.contains('Other', na=False), 'Q231_11_TEXT']
df1.loc[df1['Q212'] == 'Other', 'Q212'] = df1.loc[df1['Q212'] == 'Other', 'Q212_8_TEXT']
df1.loc[df1['Q211'].str.contains('Other', na=False), 'Q211'] = df1.loc[df1['Q211'].str.contains('Other', na=False), 'Q211_13_TEXT']
df1.loc[df1['Q214'].str.contains('Other', na=False), 'Q214'] = df1.loc[df1['Q214'].str.contains('Other', na=False), 'Q214_11_TEXT']
df1.loc[df1['Q216'].str.contains('Other', na=False), 'Q216'] = df1.loc[df1['Q216'].str.contains('Other', na=False), 'Q216_7_TEXT']
df1.loc[df1['Q217'].str.contains('Other', na=False), 'Q217'] = df1.loc[df1['Q217'].str.contains('Other', na=False), 'Q217_8_TEXT']
df1.loc[df1['Q161'] == 'Other', 'Q161'] = df1.loc[df1['Q161'] == 'Other', 'Q161_3_TEXT']
df1.loc[df1['Q162'].str.contains('Other', na=False), 'Q162'] = df1.loc[df1['Q162'].str.contains('Other', na=False), 'Q162_3_TEXT']
df1.loc[df1['Q165'].str.contains('Other', na=False), 'Q165'] = df1.loc[df1['Q165'].str.contains('Other', na=False), 'Q165_19_TEXT']

df1['Q205_1'] = df1.apply(combine_preferences, axis=1)

# Drop the irrelevant columns, decided based on potential important features
columns_to_remove = ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',
                      'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage',
                       'Q194_1', 'Q194_2', 'Q194_3', 'Q200_1', 'Q200_4',	'Q200_5',	'Q200_6',	'Q200_7',	'Q200_8',	'Q200_9',	'Q200_11', 'Q200_11_TEXT', 'Q204_8_TEXT',
                       'Q205_8_TEXT', 'Q206_8_TEXT', 'Q207', 'Q208', 'Q205_4', 'Q205_5', 'Q205_6', 'Q205_7', 'Q205_8', 'Q205_9',
                        'Q197', 'Q195_9_TEXT', 'Q210_9_TEXT', 'Q231_11_TEXT', 'Q212_8_TEXT', 'Q211_13_TEXT', 'Q214_11_TEXT', 'Q216_7_TEXT', 'Q217_8_TEXT',
                      'Q218_3_TEXT', 'Q218_8_TEXT', 'Q218_9_TEXT', 'Q218_10_TEXT', 'Q161', 'Q202',
                       'Q161_3_TEXT', 'Q162_3_TEXT', 'Q165_19_TEXT', 'Q206_8_TEXT', 'Q207', 'Q208', 'Q222', 'SolutionRevision', 'ProjectCategory', 'ProjectType']
df1 = df1.drop(columns=columns_to_remove)

# Read 'DG Post-Performance Survey - Demographics_May 22, 2024_11.14.csv'
df2 = pd.read_csv(surveyFiles[2], skiprows=[2])

# If someone responds with "Other" in a column, replace it with their corresponding text response in the next column
df2.loc[df2['Q2'] == 'Other', 'Q2'] = df2.loc[df2['Q2'] == 'Other', 'Q2_8_TEXT']
df2.loc[df2['Q120'] == 'Other', 'Q120'] = df2.loc[df2['Q120'] == 'Other', 'Q120_10_TEXT']
df2.loc[df2['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26'] = df2.loc[df2['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26_13_TEXT']
df2.loc[df2['Q161'].str.contains('Other', na=False), 'Q161'] = df2.loc[df2['Q161'].str.contains('Other', na=False), 'Q161_3_TEXT']
df2.loc[df2['Q162'] == 'Other', 'Q162'] = df2.loc[df2['Q162'] == 'Other', 'Q162_3_TEXT']
df2.loc[df2['Q164'].str.contains('Other/Prefer not to answer', na=False), 'Q164'] = df2.loc[df2['Q164'].str.contains('Other/Prefer not to answer', na=False), 'Q164_3_TEXT']
df2.loc[df2['Q165'] == 'Other', 'Q165'] = df2.loc[df2['Q165'] == 'Other', 'Q165_19_TEXT']

# Drop the irrelevant columns, decided based on potential important features
columns_to_remove = ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId',
                      'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage', 'Q2_8_TEXT', 'Q119_NPS_GROUP', 'Q119', 'Q3', 'Q153_1', 'Q153_2', 'Q153_3', 'Q153_4', 'Q153_5', 'Q153_6', 'Q153_7', 'Q153_8', 'Q153_9', 'Q132', 'Q157',
                     'Q158', 'Q13', 'Q155_1', 'Q155_2', 'Q155_3', 'Q155_5', 'Q155_6', 'Q155_7', 'Q1', 'Q3_1', 'Q3_2', 'Q3_3', 'Q3_4', 'Q3_5', 'Q3_6', 'Q3_7', 'Q3_8', 'Q3_9', 'Q120_10_TEXT',
                     'Q3_10', 'Q3_11', 'Q3_12', 'Q3_13', 'Q4_6', 'Q4_18', 'Q4_7', 'Q4_8', 'Q4_9', 'Q4_10', 'Q4_11', 'Q4_12', 'Q4_13', 'Q4_14', 'Q4_15', 'Q155_4',
                     'Q4_16', 'Q4_17', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q18', 'Q4_16.1', 'Q4_10.1', 'Q4_11.1', 'Q4_12.1', 'Q4_13.1', 'Q4_14.1', 'Q4_15.1',
                     'Q26_13_TEXT', 'Q161_3_TEXT', 'Q162_3_TEXT', 'Q164_3_TEXT', 'Q165_19_TEXT', 'SolutionRevision', 'ProjectCategory', 'ProjectType']
df2 = df2.drop(columns=columns_to_remove)

# Read 'FY24 Falstaff Post-Performance Survey_May 22, 2024_11.38.csv'
df3 = pd.read_csv(surveyFiles[3], skiprows=[2])

# If someone responds with "Other" in a column, replace it with their corresponding text response in the next column
df3.loc[df3['Q2'] == 'Other', 'Q2'] = df3.loc[df3['Q2'] == 'Other', 'Q2_8_TEXT']
df3.loc[df3['Q120'] == 'Other', 'Q120'] = df3.loc[df3['Q120'] == 'Other', 'Q120_10_TEXT']
df3.loc[df3['Q5'] == 'Other', 'Q5'] = df3.loc[df3['Q5'] == 'Other', 'Q5_22_TEXT']
df3.loc[df3['Q8'] == 'Other', 'Q8'] = df3.loc[df3['Q8_17_TEXT'] == 'Other', 'Q8_17_TEXT']
df3.loc[df3['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26'] = df3.loc[df3['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26_13_TEXT']

# Drop the irrelevant columns, decided based on potential important features
columns_to_remove = ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished',
                       'RecordedDate', 'ResponseId', 'LocationLatitude', 'LocationLongitude',
                       'DistributionChannel', 'UserLanguage', 'Q119_NPS_GROUP', 'Q119', 'Q2_8_TEXT', 'Q3', 'Q120_10_TEXT', 'Q4', 'Q6', 'Q6_21_TEXT',
                     'Q132', 'Q145', 'Q131', 'Q151', 'Q5_22_TEXT', 'Q130',
                       'Q152', 'Q143', 'Q135', 'Q18', 'Q19', 'Q19_1_TEXT', 'Q144', 'Q136', 'Q8_17_TEXT', 'Q138', 'Q140',
                       'Q141', 'Q123', 'Q146', 'Q11', 'Q3.1', 'Q3_12_TEXT', 'Q4.1', 'Q4_3_TEXT', 'Q5.1', 'Q134', 'Q134_12_TEXT',
                       'Q142', 'Q147', 'Q13', 'Q149', 'Q150', 'Q26_13_TEXT', 'Q98',
                       'SolutionRevision', 'ProjectCategory', 'ProjectType']
df3 = df3.drop(columns=columns_to_remove)

# Read 'Intelligence Post-Performance Survey_May 22, 2024_11.37.csv'
df4 = pd.read_csv(surveyFiles[4], skiprows=[2])

# If someone responds with "Other" in a column, replace it with their corresponding text response in the next column
df4.loc[df4['Q2'] == 'Other', 'Q2'] = df4.loc[df4['Q2'] == 'Other', 'Q2_8_TEXT']
df4.loc[df4['Q120'] == 'Other', 'Q120'] = df4.loc[df4['Q120'] == 'Other', 'Q120_10_TEXT']
df4.loc[df4['Q5'] == 'Other', 'Q5'] = df4.loc[df4['Q5'] == 'Other', 'Q5_22_TEXT']
df4.loc[df4['Q8'] == 'Other', 'Q8'] = df4.loc[df4['Q8_17_TEXT'] == 'Other', 'Q8_17_TEXT']
df4.loc[df4['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26'] = df4.loc[df4['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26_13_TEXT']

df4['Q27'] = df4['Q27'].str.replace('[^0-9]', '', regex=True)

# Drop the irrelevant columns, decided based on potential important features
columns_to_remove = ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished',
                       'RecordedDate', 'ResponseId', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel',
                       'UserLanguage', 'Q119_NPS_GROUP', 'Q119', 'Q2_8_TEXT', 'Q4', 'Q3', 'Q145', 'Q131', 'Q151', 'Q152', 'Q143', 'Q135', 'Q18', 'Q19', 'Q19_1_TEXT',
                       'Q144', 'Q136', 'Q8_17_TEXT', 'Q138', 'Q140', 'Q141', 'Q11', 'Q123', 'Q146',  'Q3.1', 'Q3_12_TEXT', 'Q4.1', 'Q120_10_TEXT', 'Q6', 'Q6_21_TEXT', 'Q5_22_TEXT',
                       'Q4_3_TEXT', 'Q5.1', 'Q134', 'Q134_12_TEXT', 'Q142', 'Q147', 'Q13', 'Q149', 'Q150', 'Q132', 'Q26_13_TEXT', 'Q130',
                       'Q98', 'SolutionRevision', 'ProjectCategory', 'ProjectType', 'Q123 - Actionability',
                       'Q123 - Effort', 'Q123 - Effort Numeric', 'Q123 - Emotion Intensity', 'Q123 - Emotion', 'Q123 - Parent Topics',
                       'Q123 - Sentiment Polarity', 'Q123 - Sentiment Score', 'Q123 - Sentiment', 'Q123 - Topic Sentiment Label',
                       'Q123 - Topic Sentiment Score', 'Q123 - Topics', 'Q142 - Actionability', 'Q142 - Effort', 'Q142 - Effort Numeric',
                       'Q142 - Emotion Intensity', 'Q142 - Emotion', 'Q142 - Parent Topics', 'Q142 - Sentiment Polarity',
                       'Q142 - Sentiment Score', 'Q142 - Sentiment', 'Q142 - Topic Sentiment Label', 'Q142 - Topic Sentiment Score',
                       'Q142 - Topics', 'Q146 - Actionability', 'Q146 - Effort', 'Q146 - Effort Numeric', 'Q146 - Emotion Intensity',
                       'Q146 - Emotion', 'Q146 - Parent Topics', 'Q146 - Sentiment Polarity', 'Q146 - Sentiment Score', 'Q146 - Sentiment',
                       'Q146 - Topic Sentiment Label', 'Q146 - Topic Sentiment Score', 'Q146 - Topics', 'Q142 - Topic Hierarchy Level 1']
df4 = df4.drop(columns=columns_to_remove)

# Read 'MB Post-Performance Survey - Demographics_May 22, 2024_11.24.csv'
df5 = pd.read_csv(surveyFiles[5], skiprows=[2])

# If someone responds with "Other" in a column, replace it with their corresponding text response in the next column
df5.loc[df5['Q2'] == 'Other', 'Q2'] = df5.loc[df5['Q2'] == 'Other', 'Q2_8_TEXT']
df5.loc[df5['Q120'] == 'Other', 'Q120'] = df5.loc[df5['Q120'] == 'Other', 'Q120_10_TEXT']
df5.loc[df5['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26'] = df5.loc[df5['Q26'].str.contains('Some other Race or Ethnicity', na=False), 'Q26_13_TEXT']

# Drop the irrelevant columns, decided based on potential important features
columns_to_remove = ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)',
                       'Finished', 'RecordedDate', 'ResponseId', 'LocationLatitude',
                       'LocationLongitude', 'DistributionChannel', 'UserLanguage', 'Q119_NPS_GROUP', 'Q119', 'Q2_8_TEXT',
                     'Q120_10_TEXT', 'Q3', 'Q153_1', 'Q153_2', 'Q153_3', 'Q153_4', 'Q153_5', 'Q153_6', 'Q153_7', 'Q153_8', 'Q153_9',
                       'Q132', 'Q157', 'Q158', 'Q13', 'Q155_1', 'Q155_2', 'Q155_3', 'Q155_5', 'Q155_6', 'Q155_7', 'Q26_13_TEXT', 'Q155_4',
                       'Q3.1', 'Q3_12_TEXT', 'Q4', 'Q4_3_TEXT', 'Q160', 'Q160_12_TEXT', 'Q5', 'Q18', 'Q4_16', 'Q4_10', 'Q4_11', 'Q4_12',
                       'Q4_13', 'Q4_14', 'Q4_15', 'SolutionRevision', 'ProjectCategory', 'ProjectType']

df5 = df5.drop(columns=columns_to_remove)

# Combine df0, df1, df2, df3, df4, df5 into one new file together
combined_df = pd.concat([df0, df1, df2, df3, df4, df5], ignore_index=True)

# Group by customer ID and aggregate responses
customer_responses = combined_df.groupby('ExternalReference', as_index=False).agg(lambda x: ','.join(
    [str(val) for val in x.astype(str).unique() if str(val) != 'nan']))

# Function to concatenate two values and avoid a trailing/leading comma or "nan"
def concatenate_fields(val1, val2):
    # Convert 'nan' strings to empty strings
    val1 = '' if str(val1).lower() == 'nan' else val1
    val2 = '' if str(val2).lower() == 'nan' else val2

    if val1 and val2:  # Both values are non-empty
        return f"{val1}, {val2}"
    elif val1:  # Only val1 is non-empty
        return val1
    elif val2:  # Only val2 is non-empty
        return val2
    else:  # Both values are empty
        return '' # Empty string

# Apply the function to Q27 and Q166
# Combine Q27 and Q166 into one column, as both ask for year of birth
customer_responses['Q27'] = customer_responses.apply(
    lambda row: concatenate_fields(row['Q27'], combined_df.loc[row.name, 'Q166']), axis=1
)

# Drop the Q166 column
customer_responses = customer_responses.drop(['Q166'], axis=1)

# Apply the function to Q162 and Q164
# Combine Q162 and Q164 into one column, as both ask about retirement status
customer_responses['Q162'] = customer_responses.apply(
    lambda row: concatenate_fields(row['Q162'], combined_df.loc[row.name, 'Q164']), axis=1
)

# Drop the Q164 column
customer_responses = customer_responses.drop(['Q164'], axis=1)

# Get the last row (the survey question) to use as the new header/column names
row_to_move = customer_responses.iloc[-1]
new_header = row_to_move.tolist()  # Convert the row to a list
customer_responses = customer_responses[:-1]  # Remove the last row
customer_responses.columns = new_header  # Set the new header

# Convert every row in 'External Data Reference' to numeric
customer_responses['External Data Reference'] = pd.to_numeric(customer_responses['External Data Reference'])

# Sort the DataFrame by the 'External Data Reference' column in ascending order
customer_responses = customer_responses.sort_values('External Data Reference')

# Rename columns for readability
new_column_names = [
    'customer_no',
    'subscriber_perks',
    'gain_knowledge_about_productions_through',
    'elements_like_to_include_in_experience',
    'social_media_hgo_engagement_freq',
    'preferred_marketing',
    'rate_freq_vol_of_emails',
    'other_performing_arts_supported',
    'other_ways_opera_included_in_life',
    'other_performing_arts_attend_freq',
    'other_charities_nonprofits_passionate',
    'other_live_entertainment_attend',
    'children_household_how_many',
    'children_ages',
    'children_attend_performing_arts_freq',
    'other_hgo_performances_programs_attend',
    'community_important_aspects',
    'currently_donate',
    'gender',
    'race',
    'education_level',
    'marital_status',
    'annual_income',
    'retired_ornot',
    'industry_area',
    'zipcode',
    'affiliation',
    'how_did_you_hear_about_performance',
    'programs_attended_prior_to_performance',
    'how_did_you_purchase_ticket',
    'Birth_year',
]

customer_responses.columns = new_column_names

# Remove rows with no responses across all columns
surveys1 = customer_responses.dropna(how='all')

# Save the aggregated customer responses to a new file
surveys1.to_csv('surveys1.csv', index=False)
files.download('surveys1.csv')